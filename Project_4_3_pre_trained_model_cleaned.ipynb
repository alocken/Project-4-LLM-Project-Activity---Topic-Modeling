{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "1cbmHPmWsqhB"
   },
   "outputs": [],
   "source": [
    "# **Project 4: LLM Project Activity - Topic Modeling**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "ETetHoc8bWCX"
   },
   "outputs": [],
   "source": [
    "### **Week 23** Project 4: 3-Pre-Trained-Model\n",
    "* Select a pre-trained model for your project and perform data preprocessing. (9.4)\n",
    "* Apply transfer learning concepts to enhance the model, followed by evaluating and optimizing the project model and creating an LLM Model Report. (9.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "IT6teTgw1hLg"
   },
   "outputs": [],
   "source": [
    "**Observation:**\n",
    "After research, conclude that Hugging Face's pipeline does not have built-in support for topic modeling as it does for sentiment analysis or summarization. As topic modeling is an unsupervised NLP task, will require use of a different library. In response, will use a pretrained transformer model for embedding through BERTopic.\n",
    "Notes: given this requirement, the course requests run this Hugging Face pipeline format:\n",
    "\n",
    "Hugging Face pipeline()\n",
    "data = ['list of the text for inference']\n",
    "preds = pipe(data)\n",
    "\n",
    "But as this process will use BERTopic, the following will be used to match the pipeline format and complete required passing of Text Data correctly:\n",
    "docs = ds_test_df['text'].tolist()\n",
    "topics, probs = topic_model.transform(docs)\n",
    "\n",
    "Additionally, Hugging Face pipeline expects:\n",
    "- A list of strings = returns predictions (classification, generation, etc.)\n",
    "\n",
    "BERTopic expects the same input format:\n",
    "- A list of strings (documents) = returns topics and their probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "MZSKSq5Xtjl0"
   },
   "outputs": [],
   "source": [
    "Select a pre-trained model for your project and perform data preprocessing. (9.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HQ5cGo3cbc5p",
    "outputId": "b3684b36-2bf9-49b3-e975-0d80ca6632eb"
   },
   "outputs": [],
   "source": [
    "#install required packages\n",
    "!pip install bertopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 621,
     "referenced_widgets": [
      "b4a9af64f13945f48b2b1b4464aaf836",
      "fe570c5aafae4fc2809e13e1107b9ab7",
      "3ce2b3cf41e84393a0234d17a9c395a3",
      "7a79f5564db24d16a62ab47b08cb9535",
      "9dbfd566a0ec48379291349d00700228",
      "d3e50eda578e46e492497aac9bc05545",
      "6b4a4433ac9940b98c7cbf206fce2f6f",
      "d76f07985a2d4071bf57b6098c00ce2c",
      "b47fc62f6b3f49f9a53be40c83db400b",
      "81b4bb05d55f40fdb7d74c3b42cad5d6",
      "ed52bfb8cb9c4a16b842713e5fb38ec2",
      "f870fe1f77eb412ebc8de3e504850436",
      "b611e7a0b018486cb60c5c37766a4272",
      "a32cbabb9aa14101be9c136ff67799d0",
      "9bc53c5caac24efdae2cbf0b1c97a352",
      "a87d3ec0650143049d44080ce45a65db",
      "edb9711812b144aba559247e3e57ef45",
      "be305c235a9b48908aab8be2d3a380af",
      "d357b0ebecf24f2fab5d6cc872599d56",
      "4429a2934fbc4ac6bbe44e07bbb77066",
      "b6cd0329f4144690a9e73c96557bd9cd",
      "13490d7caa304ec4b9092df114f93bbf",
      "9bdfa5d0f5554c6ab3f44717f813b2f3",
      "ec297e7bc43e47b5968a72e84da99590",
      "ec0613453ee84d0ca9a0ea3ee7271845",
      "523deb7d4d6a406f83ffc4c486ee438d",
      "d15de429015d4923b1555b709e682519",
      "d1b2e672f78c493db8dcfe0fccb351a5",
      "7d3c180741dd446282127e63737c2530",
      "d1a594e5dccf4c78a5dceb3a7f0d5828",
      "72069a8893334ae6b417c644bd601d2c",
      "5a7fe5f3e52f43e5afda28b0ef2e47dc",
      "58eaead643d740dbb823a9a09d1beab1",
      "2a963a242c204a909be490fa13ae6187",
      "ebca8b14d9834ff3a5d9b68476d4367c",
      "e78f13b7bd0b45dba9341a0971e959d7",
      "bd1523507e1c412b8b98a8c6a8eacbb4",
      "5fdcb893dd834682bdb804095c743110",
      "f434b05e73d84b89820cdca3cd024ea6",
      "32ee2eeb9f194878ba49afca5ca2b801",
      "67d35472cfb7433cbdd42d0b6ff261eb",
      "3e8c0cc03bed48afbf3d31a42ee1e25f",
      "f1014cb8c1ad41a4ba5c0bc21f0c11b5",
      "e2a55f11d4504e9a842f9d322dde6caa",
      "900e152b8790487ea78fb4822301f5d2",
      "2ab08ad6b1864302ace466fb7eff6909",
      "b73783566c6f44a69c8bace4a3fd1372",
      "e80e68dec7604f79b572f6fcfd34f5f1",
      "08ced867efa447e68f0556e592e7d614",
      "d6bf62fd0534440a843b6318e08f3be2",
      "7e94742ba3c4406ca3e0b9ffab275a47",
      "cd5e0bfd30f0413ab3f8775992656ecd",
      "e6da56eb2fa9404cbc3255b8c8be649c",
      "a591fc703b3f433088b20a9fc7ebecf9",
      "b17eedf0838c4169bb984e98a76b5be2"
     ]
    },
    "id": "xhAoZj6NbfIE",
    "outputId": "4cdfc76f-b123-4584-e7b1-673ca63a9129"
   },
   "outputs": [],
   "source": [
    "#selected and loaded pre-trained BERTopic model from Hugging Face\n",
    "from bertopic import BERTopic\n",
    "topic_model = BERTopic.load(\"guibvieira/topic_modelling\")\n",
    "\n",
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v72V8hHB6ByU",
    "outputId": "183fb8dd-28b5-4136-a47a-04c8db55ac30"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "!pip install -U fsspec datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3oNupudQ51RO",
    "outputId": "73bd4c30-f1bf-443a-8554-7281d3893860"
   },
   "outputs": [],
   "source": [
    "ds = load_dataset('SetFit/20_newsgroups')\n",
    "import pandas as pd\n",
    "ds_train = pd.DataFrame(ds['train'])\n",
    "ds_test = pd.DataFrame(ds['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VqqGymg05ah1"
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "train = Dataset.from_pandas(ds_train)\n",
    "test = Dataset.from_pandas(ds_test)\n",
    "\n",
    "new_ds = DatasetDict({\n",
    "    'train': train,\n",
    "    'test': test\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kAM4JUwlsw6w",
    "outputId": "6327176d-90d1-4185-e9b0-5898ad2c35eb"
   },
   "outputs": [],
   "source": [
    "#pre-processing to improve embeddings and clustering quality in BERTopic\n",
    "#text cleaning\n",
    "import pandas as pd # Import pandas if not already imported\n",
    "from datasets import load_dataset # Import load_dataset if not already imported\n",
    "import re\n",
    "\n",
    "# Load the dataset and convert to DataFrame if not already available\n",
    "if 'ds_test' not in globals():\n",
    "    ds = load_dataset('SetFit/20_newsgroups')\n",
    "    ds_test = pd.DataFrame(ds['test'])\n",
    "\n",
    "# Define 'docs' from the 'text' column of ds_test\n",
    "docs = ds_test['text'].tolist()\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower() #lowercase\n",
    "    text = re.sub(r\"http\\S+\", \"\", text) #remove URLs\n",
    "    text = re.sub(r\"\\n|\\r\", \" \", text) #remove newlines\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text) #remove punctuation/symbols\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip() #remove extra spaces\n",
    "    return text\n",
    "\n",
    "docs = [clean_text(doc) for doc in docs]\n",
    "\n",
    "#pre-processing stowpword removal\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    return \" \".join([word for word in text.split() if word not in stop_words])\n",
    "\n",
    "docs = [remove_stopwords(doc) for doc in docs]\n",
    "\n",
    "#lemmatization/stemming (reduce words to root form)\n",
    "import spacy\n",
    "# Download the spacy model if not already downloaded\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    !python -m spacy download en_core_web_sm\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    doc = nlp(text)\n",
    "    return \" \".join([token.lemma_ for token in doc if token.lemma_ != \"-PRON-\"])\n",
    "\n",
    "docs = [lemmatize_text(doc) for doc in docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "BFAxTokvs2gu"
   },
   "outputs": [],
   "source": [
    "Given this is a BERTopic model, transfer learning applies to the embedding model, not the topic model itself. The transfer learning will be using a pre-trained sentence transformer and fine-tuning the embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369,
     "referenced_widgets": [
      "7d01e85adb214387ab5ba6e5ade91093",
      "e4549d5491b444849ffe4d9679662ea7",
      "3e5c052b8ca7442e8e49336c3bffa92d",
      "9bef78cd77134c8fae0d1be564204d1a",
      "f68007ba704e4760bf91abfcb7b361e0",
      "ece944662b1d4785a5f51609dc67b24e",
      "8683ee975dff49baa22710e313c7e42d",
      "7dc52b52281248308d2a4f615a9d8f36",
      "6eec4a93a2da4440893e4b68ba23425b",
      "99e061b6c13048ab96b2a6641b97da75",
      "62a92278061748299a80ae02199264dd",
      "74b5ae43b2a24c80a5ea633183abcd8a",
      "9c0d6a698d304f1ba4b7db71d0f35766",
      "5440a24e3dce47f69ba585ab10df9ac4",
      "6629eb8d3a35465d925d8e8daebe0114",
      "d1276b822e37497d81aea4041c0bdd2d",
      "899efa7d27554e1f81abcd0cac2205a8",
      "8a978a56155a4fbbbbce24d7b1b489f5",
      "7b312c3be34f4449b1bf6e97a94ecbc4",
      "9319a2ef48e34a6688cb28defcee823f",
      "39a76737dce640e3916e97dd27421aca",
      "8b2e8b90d68d4d36b9d35421f6c6ae82",
      "55aea745bf684554b1b5aafe9903c6c6",
      "1efed53cc9774bfbaf74a46dd3600797",
      "80a79222e34b4ef7880054885861fd25",
      "344b09dbf0a24203bebe88afabf49cc8",
      "afc568ec88d34b2b9d67435cf6f7eecc",
      "186f625aad5f4d76bc19fc100e37defc",
      "042f481a31eb44b198f802e8a264ee58",
      "8088dc493a644d028935ea8b4a6a0b22",
      "afb2907453f74c79a030dcc31e1df7cd",
      "6bdabd47f607447792cb27993e7c1076",
      "adbd9fa7659049a89ea7566eed9713b5",
      "6013390da7764ce7886ebc32234b8fef",
      "2fe4f3f3ea1446069b01685693013eef",
      "85377e47e7d54f49be843e5da702d5ed",
      "b09c5405ac4a4ee2aea6e30837026d35",
      "b8ee332e4c3c44ee8ff4f0e5d5741fb5",
      "f9b2c6de33db4a1283c5769c4c688d22",
      "f88ab09b1b9449108bb07993fa2f684f",
      "ab90f036e5ac4285a869ac7287072dec",
      "b1441d6e0915421eb57a643c665b2e5e",
      "8de4808b8e76499cbd0c64872dfc90e5",
      "2f1fec144bf2466bb5b360c69f671cc1",
      "2ad8df45882a4b0abdff3362c8e21ba2",
      "1b05d02791b64d7a8e04ed1bce9cc283",
      "ffd58d2d8eab4c3bae2611f92fb24140",
      "747353e01338417f9832ccc407bd2eb3",
      "07b9e79827d44b32bfbedb927839a4fd",
      "188717bfe8834cd8971d7284a5788edc",
      "5d08dd8d9b6f4cec913534b372077670",
      "f0b3c69e3ca2463283e70c2d2cd07447",
      "7bdf15c30f3b46d28c7a546ccf924497",
      "91944466f90e4b80acecf26f5b60fe27",
      "88ea4cc56a4f4520814b2fd7a2ccd638",
      "4e936f61228d4da795a202e00ee11e91",
      "308420d7080249e391f3cfab465648f7",
      "f5f7e726f8384cb5916334141f6866b1",
      "3b7155456a73455c938cd9c798640f50",
      "0836ace63d7749f5a825923a55408fd7",
      "f98898a616d64c959f8731bdd06983d9",
      "61d6857d9e4f43d8b6e1f3687a34f52e",
      "05e0012bc86b45cdb6cef06c505d1b68",
      "61cc562913ff4dc3bb74213cdf1cc2f8",
      "d0d1f72c63b14594a648368d6b83df7b",
      "b79d7006f29c40c9b6e6eb0f322f7e35",
      "9fa6e674ba5449438b3700e18a3a35ad",
      "1d58376d710f457aa12bbcae9ca713ef",
      "c02fc31e6a5c4b848874e7866ca28477",
      "5b1e372fb6eb44ae8ba3521d8aa8903a",
      "b97b1983e5e14a4389ee34b7ff5c2a82",
      "98d633b68fcf4d58895972c3af4de1d5",
      "2e9983d19f87431e84729043ed1be228",
      "16f25eef1b4b44e8a1ec040c0d98984a",
      "29508fcd4492435baa146d952530fca3",
      "ffeb056694e2475d85e3b0ed419ed36b",
      "8698e96d4f8b45d583181a25c87eb811",
      "2912e9991fb048abbee3dcd66d44cdcf",
      "ec7cbbbbdc1d426e8e9e31db12d08a22",
      "bd5a5001840c4571b459941d3d5a68d3",
      "2cf44158dc4c4c5b83963cbbec2f5316",
      "aa32dc5b065f4aae809b3c58d65923a4",
      "7e330d300bc24311842cb6d8fed6a38a",
      "a06e4f99f9b748d4b1f741ef4339a76c",
      "82d6cf7bc089464a83ada4797d0e9ef5",
      "df5c3f58e3594d1fb55aa7d54744f920",
      "62311f198acb44e0acf1bea1575f7fc1",
      "d957a4aba7a4462981642def4b33dd1f",
      "a6e03011439a44019a1b81a936d57488",
      "5b13ab3789d44cff8d5aca6f7f2c6ebf",
      "dfbae03cbc894a3ea486bfda46683281",
      "aa7d89c0c8104c5fad563324b78c1718",
      "3048cf278e7c4f9d98365d7e4a9aae66",
      "b7a09d32a4534969bad09f3c2745460d",
      "782128a48f354c4597ef72e14434f649",
      "bb81c058e8204b06a1dd9110de45a212",
      "74f1bfd35ff1479799c86c0ca9992ebd",
      "c184c5ef80cb4090beaf52468ff521b2",
      "b5e8efa1e9dc4485ba8ab1e3d9978354",
      "1c0707ead7fe4d3c9a887ea18628367f",
      "59ae6e14aeb949cfa65826d5dfe14368",
      "f57520b680bc4ae3b3790c8af55a6ded",
      "055d958b6a0b4ada869d78b735ba7b18",
      "743d579cc1254083b59bd246e067b482",
      "05168091f3f0424982c9a8c68252c2fa",
      "f49cd173151a4502a3c23c2c2e0e3d49",
      "a8e1232ebf724a3a94f48261cf3656d8",
      "f5da3d621e334a8fa5baff74b2a41fdf",
      "19afa7e8c32b4ca095bcdea598e7c057",
      "0cc19fc2565c4bec884e37715872bb0d",
      "d60faa2ffed44b3cbf151cd12e462b02",
      "78b880a9ca1c492e9a132795f833ace1",
      "02d885700aad468589d0a3b59cfe9720",
      "eb9c37309e274e54b746ceabf8fe55fd",
      "ccc4e0480adc424ebf078989d996aaea",
      "e59028bc75f94a7fa6831283e9137c34",
      "cb3c179826464a7f93733eff60e23381",
      "25891361d7ce4660bfa92a029c00cfbc",
      "f850a7b0fd5e4c9a987058f2f91b2a20",
      "2e0edaf9e4a14bd0910006aac9fdb1f6",
      "5aaef89543e6449bb254ab11687219af"
     ]
    },
    "id": "4A6TXTuj6Yb_",
    "outputId": "98c4eddd-e608-49a2-8254-4acc2ea74914"
   },
   "outputs": [],
   "source": [
    "#topic model requires embedding model specified explicitly, added code to address error\n",
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "#load sentence transformer embedding model; note: automatically includes tokenizer 'sentence transformers' embedded in BERTopic handling internally\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "#load BERTopic with pretrained topic model AND embedding model\n",
    "topic_model = BERTopic.load(\"guibvieira/topic_modelling\", embedding_model=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "4e770bb381504ae089464cfe079afc89",
      "ffdea05164624421afb6e47c45160695",
      "75320058fb484f26b0d4fd031802fa68",
      "4b8751a46f9f489eb62f6fe960b30092",
      "e635152f17e84ac092551655c8bc3b77",
      "3d78cae15cb84583afc545ac0087b9e5",
      "b71f20eeff064ea7bf1773260d810edd",
      "29d3bd5fae534e6890791451791b35a6",
      "68ccac7b3c204762a688f9b993caa8d9",
      "8f049c076b604e589218f771a9e600e3",
      "6911650047a74cbd98516011c6d3567a"
     ]
    },
    "id": "AnyJmuVe5O8e",
    "outputId": "4bc0b047-cd44-44c1-e98d-4000590e43d7"
   },
   "outputs": [],
   "source": [
    "# Convert Hugging Face test set back to pandas DataFrame\n",
    "ds_test_df = new_ds['test'].to_pandas()\n",
    "docs = ds_test_df['text'].tolist()\n",
    "\n",
    "# Run BERTopic\n",
    "topics, probs = topic_model.transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "L5eGq0WM-PPN",
    "outputId": "641762f0-bf81-482a-b64d-42634f0c678a"
   },
   "outputs": [],
   "source": [
    "# See an overview of the topics (topic IDs, counts, names)\n",
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UbzZfEXc-lpl",
    "outputId": "dddc95c8-9522-474b-d2a5-8fab35b22f76"
   },
   "outputs": [],
   "source": [
    "#see all topic IDs (top 25) with top words in DF, sorted by count (descending)\n",
    "topic_info = topic_model.get_topic_info()\n",
    "top_topics = topic_info[topic_info['Topic'] != -1].head(25)  # Exclude outliers (-1)\n",
    "\n",
    "# Print top 25 topics with keywords\n",
    "for topic_id in top_topics['Topic']:\n",
    "    print(f\"\\nTopic {topic_id}:\")\n",
    "    print(topic_model.get_topic(topic_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vWUdsNev-_KG",
    "outputId": "3b95c4fc-0bb9-4ede-cf47-912dd3c5e4e0"
   },
   "outputs": [],
   "source": [
    "#inspect predictions (topics per document)\n",
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    \"document\": docs,\n",
    "    \"topic\": topics,\n",
    "    \"probability\": probs\n",
    "})\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "Wkbo84lSEoEj"
   },
   "outputs": [],
   "source": [
    "Notes on predictions output:\n",
    "\n",
    "A higher probability (closer to 1.0) means the model is more confident in the topic assignment.\n",
    "\n",
    "A lower probability (closer to 0.0) means the document is less clearly matched to a topic.\n",
    "\n",
    "If the topic were -1, it would mean the model considers the document an outlier that doesn't fit any topic well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "trpZ5_jv_BkW",
    "outputId": "0db7443c-0dfc-481e-bd28-e0ed751f0e4d"
   },
   "outputs": [],
   "source": [
    "#how many labels (topics) predicted; unique topics (excluding -1 which means 'no topic assigned')\n",
    "unique_topics = set(topics)\n",
    "n_topics = len([t for t in unique_topics if t != -1])\n",
    "print(f\"Number of topics found: {n_topics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "4hl3YxOP_SIa",
    "outputId": "c6020379-da32-4086-e943-0c2740bf7bf5"
   },
   "outputs": [],
   "source": [
    "#summary of all topics\n",
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "9iu-moKMx3SD"
   },
   "outputs": [],
   "source": [
    "Apply transfer learning concepts to enhance the model, followed by evaluating and optimizing the project model and creating an LLM Model Report. (9.5)\n",
    "\n",
    "From Hugging Face transformer documentation task guide, natural language processing, selected the text classifciation to apply as it may be the best fit for transfer learning in topic modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RpMjQRlewV7G",
    "outputId": "8c47884f-2483-4fb5-b002-67fe3f969bcc"
   },
   "outputs": [],
   "source": [
    "#text classfication - load necessary libraries from Hugging face\n",
    "!pip install transformers datasets evaluate accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JG72FizrwV4b",
    "outputId": "69c281ec-922d-4326-fdc0-5853e9cc3376"
   },
   "outputs": [],
   "source": [
    "#load data set\n",
    "from datasets import load_dataset\n",
    "ds = load_dataset('SetFit/20_newsgroups')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fmWttYZTwV1Z",
    "outputId": "be50ae31-2a16-4e2d-9580-734227a9f1c8"
   },
   "outputs": [],
   "source": [
    "print(ds[\"test\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "2c54419bf42c444dbebc0fcbd122dab2",
      "29d4bd85906a48d99cf0d33c2ebd4e18",
      "a39eb28e2005488cb0cf5a19ab9058ee",
      "cdc8734a955746ea97585d2ebf399989",
      "2e3f59dbb01c46aa9f887bb6081907fd",
      "8312b11cf1fc44858d5a3d28172a3147",
      "aecebe2ee48f44ca841420b738345418",
      "23370fd458334f4da3837cbaaa5a3c4a",
      "9bec90d3565d49b589a28be8ee8c1347",
      "24a520e9baed431a8a7b58c9d060338e",
      "2b6b0db06b6a4b489d1e0b3b70760762",
      "9d9fbb4ace3b4fa5a69bca729672d257",
      "dd90d46d9eeb41d0a10eb63b952b60c9",
      "d9f41ea211bf4528a0818058d958cb1f",
      "9642faf69c424fc7a1121e4d4daa161e",
      "5b395224db0f41c6b3cfaf674e8dcdfe",
      "88d818f0782c47d78adefd6b9911cb69",
      "e7224ce8069a494fa202120923396d49",
      "c2c04d63c21b4c439c28e6b3df3bc16e",
      "31848b1c53b643289ebbd6894fdb8309",
      "48871ae0681c4e65bb24d90adf1f39aa",
      "44d5b55d94eb4e978cbf867477d5f2da",
      "87890a52ae9c493d999deca5c4248f85",
      "d13a883399b7450a914cf5bdbe6d9679",
      "41787bc628bc41f2a372be6b4468c9c0",
      "f8366c3435a94ccba3841436deb5c2dd",
      "94445dc3f80942679709ba2211cf0ceb",
      "be01f798e5da46e1a562c554c313f38d",
      "33b87e46dd7b4b3391e5d56d998d143b",
      "48102fe181f04e5b9a1c01bc11ade185",
      "f58f45b2dee1464b99417d555ceead1e",
      "eeba1639e57d477388a2113bf00b9e15",
      "0b32495594c94af6a05fadaea714e663",
      "a636deeaf2dd4c2092fcc876d836a02e",
      "dba37e56e20944fc9313e3b48f27fd87",
      "a53e3dcdc71847919a45447ccadb5ea8",
      "00d3a5de42bb472492e6fd876c4d090b",
      "1b60292f0c75494c985027fa4b174882",
      "f1416e26d4074ca1b5d8b943fc851e53",
      "f4208643726f4655a8780d58238a3874",
      "3adb441c24d54cb39f2cc5a716f384c7",
      "d7484fb72ed84d2cb748a6034bc58b99",
      "a3aa17437a9947f8b3cd832f1e095b5a",
      "8c77702f90254c948f828724d0571fda"
     ]
    },
    "id": "urMmeKyHwVtn",
    "outputId": "b9ee607a-39dd-4d8d-8fef-5356793f3848"
   },
   "outputs": [],
   "source": [
    "#preprocess load DistilBERT tokenizer to prepcess text field\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "36170338f97d4b2e8fd6f35ef47719ea",
      "8e9b21553a8d4355a1efac28b1fcf264",
      "50adbfcc3aa340f390f0d53bfaa4c080",
      "0881d55be0e2465f97ab81715a371113",
      "958d5fa56142409ebc5b142d78b04023",
      "8adef37216e7414cbcc5327f0a302d41",
      "5b427422ce5c4a43b26aa7f58653b4e9",
      "fcaac40a841643e1906011cd73f89088",
      "6e78af4308cc4df6b0e53260847eaab6",
      "e1943e632c404048b98d0723ff767c0c",
      "67db2eab781049c98a63139fe89a3a38",
      "25d207c8833d4bf68e47813bcafa348f",
      "9c6213cdc4444107b82a2cb38c4cec98",
      "b94f8dc8b72f43078e1bd827cbdac80e",
      "b5a16e4ba07f41f8829e22501992958c",
      "b810a90df621442ea8fcd97f16cc9687",
      "3d61ccd9a3f64e14b42cef54a7b3e51b",
      "e680c684580b44a892cf53e87bfeeb0f",
      "0cb2213c5067433fa15a225773b5a631",
      "7270a8ebb8a54fdc9fb244645cdc779c",
      "3cee05eaa9d944fd9735222e2ad06fe7",
      "fd8ce8657ed44d369d1e5d66474f44cd"
     ]
    },
    "id": "tLYZ5dSG0mzJ",
    "outputId": "f94007ec-3101-4718-84d9-97cc92c20cef"
   },
   "outputs": [],
   "source": [
    "#create preprocessing function to tokenize text and truncate sequences to no longer than DistilBERT's max input length\n",
    "# Define preprocessing function\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=True)\n",
    "\n",
    "# Tokenize all splits\n",
    "tokenized_ds = ds.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MmsX1zabA8-b"
   },
   "outputs": [],
   "source": [
    "train_ds = tokenized_ds[\"train\"]\n",
    "eval_ds = tokenized_ds[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KQCCcvaR05gh"
   },
   "outputs": [],
   "source": [
    "#create batch examples with DataCollatorWithPadding\n",
    "#Pytorch\n",
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "a56461efb8ad4671912baa6a7bd526ad",
      "bf78898055504f318e8732fdf7bc53e1",
      "6115272158b246e682b6722eaa270936",
      "4c8569a2598a4299bc18a9b917bb0eb4",
      "27d65633419647c1a1bacea068c13627",
      "745a32d3043c465f860d5b9f5c63a16c",
      "022e59fd2e0d494f962b202a24cbcee3",
      "d78c2d6defcc45ba879a96a3dad6ab1b",
      "78028e627fa948f1bcc0185a5d56acf7",
      "f7b9e5a8f00542219704b68e4d724be8",
      "f67a0dcd187244c0a5d6846967b77df1"
     ]
    },
    "id": "14hpZKhX05dt",
    "outputId": "4c58e5fe-b28c-450e-9977-b1f025a9e7a9"
   },
   "outputs": [],
   "source": [
    "#Evaluate model performance\n",
    "import evaluate\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "07B189k005bB"
   },
   "outputs": [],
   "source": [
    "#function to pass predictions and labels to compute calculate accuracy\n",
    "import numpy as np\n",
    "from evaluate import load  #Hugging Face's metric loading\n",
    "\n",
    "accuracy = load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QDZSGCyE--yB",
    "outputId": "6bccf239-67f3-4159-8161-9f567b2f9588"
   },
   "outputs": [],
   "source": [
    "#check dataset labels\n",
    "print(set(ds[\"train\"][\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "algQ9b1e_Hyj"
   },
   "outputs": [],
   "source": [
    "#before training, map expected ids to labels\n",
    "#manually define label names\n",
    "label_names = [\n",
    "    'alt.atheism',\n",
    "    'comp.graphics',\n",
    "    'comp.os.ms-windows.misc',\n",
    "    'comp.sys.ibm.pc.hardware',\n",
    "    'comp.sys.mac.hardware',\n",
    "    'comp.windows.x',\n",
    "    'misc.forsale',\n",
    "    'rec.autos',\n",
    "    'rec.motorcycles',\n",
    "    'rec.sport.baseball',\n",
    "    'rec.sport.hockey',\n",
    "    'sci.crypt',\n",
    "    'sci.electronics',\n",
    "    'sci.med',\n",
    "    'sci.space',\n",
    "    'soc.religion.christian',\n",
    "    'talk.politics.guns',\n",
    "    'talk.politics.mideast',\n",
    "    'talk.politics.misc',\n",
    "    'talk.religion.misc'\n",
    "]\n",
    "\n",
    "# Create mappings\n",
    "id2label = {i: label for i, label in enumerate(label_names)}\n",
    "label2id = {label: i for i, label in enumerate(label_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104,
     "referenced_widgets": [
      "8b112fd132124095a561ab2ee14fd1d5",
      "892be64645a7414bb26ad1e6ec64c620",
      "a7657837ada34b1a849f5053687bce10",
      "bdae8a7d27a84d0286e7004883050cb8",
      "4b7cb8077b784ea1bbf919de72c1094b",
      "3784d86d6f234a1d8f84b262f497e31d",
      "81703d2cbf09413babb3411305462c16",
      "25f21d0049094b81b6cea4d9ddb6f7e6",
      "5e26f15323fe4066a2560b7e188a4de6",
      "1e8d7c1cc0f448e8b09acfee07ea1435",
      "ae2223ec3be0416b9c1fc5d175f4419c"
     ]
    },
    "id": "G92KmDPf1l4F",
    "outputId": "e6fede5f-1d69-4ade-aab8-70d8aced60ee"
   },
   "outputs": [],
   "source": [
    "#train model, load DistilBert\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\",\n",
    "    num_labels=len(label_names),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "335d239f1bda4d8e8a3e04d52b6ee3bd",
      "61a41755e3c5448fbad60ef3d9b302dc",
      "71e2f909446a475e8dee56db7a5427b5",
      "286dd2323a1940118b8dc72d2e7be96c",
      "91cbe0b2351e44319118489c1e0117b0",
      "1b779692e1be4b499d54fe341d8aac41",
      "f80177fd43854c689869b17debb7c035",
      "1cf1b24323a545f08fa48e0e09ba4e64",
      "091f4a92d3b74c98aa58029caffd841b",
      "a6af60d97fb04035894ac187ef4ea363",
      "bc0898a8180540c78f74c2c82f73094f",
      "b6eafc06ad9d4ffd9e85cb333508258b",
      "3d9a92b59c234a3898f581ea802aae07",
      "a4d9103edacd4be2abc327d2ee86bb5f",
      "b378c5f1f7114e83938abceb8cc5ca6b",
      "ec435094480243d0b9a22e43f1f0353a",
      "744a422c94c84c8fa4cc852ff868102c",
      "20ba7475bf8b4428a707cdbde0d61192",
      "65a91f15e45847ecba7784c939044a29",
      "c5bc2b34f494481387eaf027e5a554e6",
      "dbf8eed7567449b2ad9f67c4ce38215c",
      "3e7fdd7b9a0e4ecb87e536fc4a5aab0f",
      "a218ebcf5ddc4b389ed896e169292da5",
      "a7afa28fdf8f45d2aa3734b6500fb27a",
      "838738a9283f45e3bf7bc37bbf768628",
      "93eea5fee4184e67ac18c41d8cfffd29",
      "b7968990f17e4e0a8045a2e228d148e8",
      "f97a457aa8f74dc8b6fae5405b1eec09",
      "03e487048d004001a9d78d57209698b5",
      "0df3cbb3f3644694b7244d7332d15fb8",
      "7016766a460f43478ccbc9da8b89b650",
      "a11fad59a54945bf8782150c364f81e0",
      "5e2a11bada494a4c85c21773bb26f19b",
      "6cd0c888b29749588f939bfda66e57aa",
      "2c42aec35fd6452aa827a971ffc9bb22",
      "bfeed14373894424992a7d5d9dd25829",
      "566a5f6765eb4db2be9d3be3a1e71241",
      "d77d1b12625b4704a91bd7334845639d",
      "0a60781568714b09be8f34a0f43b83e2",
      "d68916d088e64d33b334a423fc83b913",
      "e7ed1749e4d2407e86c16076382c3bea",
      "3d91a378dbf74cf58fbc7dd1e4927fc9",
      "d5104897865346edbb1de63cb4810a42",
      "03e345190787410abbb95882bfb26811"
     ]
    },
    "id": "oSDROKaxCeN8",
    "outputId": "98a30762-d12f-4b28-bd20-baf62d4158ed"
   },
   "outputs": [],
   "source": [
    "#define training hyperparameters in TrainingArguments, choose appropriate metric for model to calculate metrics during training, pass training arguments to Trainer, call train() to finetune model;F1 will determine best model at end\n",
    "#metrics selected: accuracy overall percentage of correctly classified documents and Macro F1 Score to determine mean of precision/recall per class and averaged\n",
    "import numpy as np\n",
    "from evaluate import load\n",
    "\n",
    "# Load all required metrics\n",
    "accuracy = load(\"accuracy\")\n",
    "f1 = load(\"f1\")\n",
    "precision = load(\"precision\")\n",
    "recall = load(\"recall\")\n",
    "roc_auc = load(\"roc_auc\")  # AUC for multi-class classification\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
    "        \"f1_macro\": f1.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"],\n",
    "        \"precision\": precision.compute(predictions=preds, references=labels, average=\"macro\")[\"precision\"],\n",
    "        \"recall\": recall.compute(predictions=preds, references=labels, average=\"macro\")[\"recall\"],\n",
    "        \"roc_auc_ovr\": roc_auc.compute(prediction_scores=logits, references=labels, average=\"macro\", multi_class=\"ovr\")[\"roc_auc\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-NiEYs2T7B_9"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"newsgroups_model\",             #checkpoints & model are saved\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=1,\n",
    "    push_to_hub=False,\n",
    "    save_strategy=\"steps\",             # save checkpoints every N steps\n",
    "    save_steps=25,\n",
    "    save_total_limit=3,                # keep last 3 checkpoints to save disk space\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-qIiUg3O1luw"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=eval_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fxqDwSr165Sn"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "ZTUEjyAWG89a",
    "outputId": "b683b9d6-aa73-4a67-973a-dbe3a961c88f"
   },
   "outputs": [],
   "source": [
    "import nbformat\n",
    "\n",
    "input_path = \"Project_4_3_pre-trained_model.ipynb\"\n",
    "output_path = \"Project_4_3_pre-trained_model_cleaned.ipynb\"\n",
    "\n",
    "# Load the notebook\n",
    "with open(input_path, 'r', encoding='utf-8') as f:\n",
    "    nb = nbformat.read(f, as_version=4)\n",
    "\n",
    "# Clear notebook-level metadata\n",
    "nb.metadata = {}\n",
    "\n",
    "# Clean each cell\n",
    "for cell in nb.cells:\n",
    "    cell.outputs = []\n",
    "    cell.execution_count = None\n",
    "    cell.metadata = {}\n",
    "\n",
    "# Save cleaned notebook\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    nbformat.write(nb, f)\n",
    "\n",
    "print(f\"Cleaned notebook saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AMZULzUgHSZp",
    "outputId": "164c0dd0-ad76-4e21-dcff-4bcb7cdb36f4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
