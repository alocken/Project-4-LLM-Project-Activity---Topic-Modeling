{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project 4: LLM Project Activity - Topic Modeling**\n",
        "### **Week 23** 2-Representation\n",
        "Apply tokenization and text representation methods in the project. (9.3)\n",
        "\n",
        "- Input text and preprocessing completed in notebook 1_preprocessing.\n",
        "- Also, tokenization was evaluated and applied in notebook 1_preprocessing (tokenization cleaned text, normalized text, and split on spaces). For this notebook, added in how many documents are in the dataset and how many total words make up the vocabulary in the dataset after tokenization from notebook 1.\n",
        "- Next, in text representation, will be to complete vectorization using chosen method of TF-IDF resulting in output of vectorized text. In this step, removing notebook 1 tokenization will be required to pass into the TF-IDF as a string and then TF-IDF will re-tokenize those strings as part of the building feature matrix. A re-check on the number of documents and total words in the retokenized output will be completed again at this stage to ensure completion/for reference.\n",
        "- From this, will selected to build a Logistic Regression ML model and its performance will be evaluated against test data."
      ],
      "metadata": {
        "id": "Jf6LsawNkiuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Number of documents and total words vocabulary after tokenization (notebook 1_preprocessing) - documents, words, vocabulary size\n",
        "#Train dataset\n",
        "num_documents_train = len(ds_train)\n",
        "all_tokens_train = [token for tokens in ds_train['text'] for token in tokens]\n",
        "total_words_train = len(all_tokens_train)\n",
        "vocab_size_train = len(set(all_tokens_train))\n",
        "\n",
        "#Test dataset\n",
        "num_documents_test = len(ds_test)\n",
        "all_tokens_test = [token for tokens in ds_test['text'] for token in tokens]\n",
        "total_words_test = len(all_tokens_test)\n",
        "vocab_size_test = len(set(all_tokens_test))\n",
        "\n",
        "print(f\"Train documents: {num_documents_train}\")\n",
        "print(f\"Train total words (tokens): {total_words_train}\")\n",
        "print(f\"Train vocabulary size (unique words): {vocab_size_train}\\n\")\n",
        "\n",
        "print(f\"Test documents: {num_documents_test}\")\n",
        "print(f\"Test total words (tokens): {total_words_test}\")\n",
        "print(f\"Test vocabulary size (unique words): {vocab_size_test}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNbjiSwTsvXd",
        "outputId": "7f4255ef-b5ac-493c-f0a9-7b03d5a93cc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train documents: 11314\n",
            "Train total words (tokens): 1166464\n",
            "Train vocabulary size (unique words): 101919\n",
            "\n",
            "Test documents: 7532\n",
            "Test total words (tokens): 730769\n",
            "Test vocabulary size (unique words): 73050\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Vectorization using TF-IDF to convert text into numerical features\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "#Detokenize\n",
        "train_texts = [' '.join(tokens) if isinstance(tokens, list) else tokens for tokens in new_ds['train']['text']]\n",
        "test_texts = [' '.join(tokens) if isinstance(tokens, list) else tokens for tokens in new_ds['test']['text']]\n",
        "\n",
        "#Create TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "#Fit on training data and transform\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(train_texts)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(test_texts)"
      ],
      "metadata": {
        "id": "3YlaTGlGqlUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Output of vectorized text - documents, words, vocabulary size\n",
        "def dataset_stats(ds):\n",
        "    num_documents = len(ds)\n",
        "    all_tokens = [token for tokens in ds['text'] for token in tokens]\n",
        "    total_words = len(all_tokens)\n",
        "    vocab_size = len(set(all_tokens))\n",
        "    return num_documents, total_words, vocab_size\n",
        "\n",
        "# For train set\n",
        "train_num_docs, train_total_words, train_vocab_size = dataset_stats(ds_train)\n",
        "\n",
        "# For test set\n",
        "test_num_docs, test_total_words, test_vocab_size = dataset_stats(ds_test)\n",
        "\n",
        "print(f\"Train set - Documents: {train_num_docs}, Total words: {train_total_words}, Vocabulary size: {train_vocab_size}\")\n",
        "print(f\"Test set  - Documents: {test_num_docs}, Total words: {test_total_words}, Vocabulary size: {test_vocab_size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2C0m_UPv1_V",
        "outputId": "6128b9ef-778e-41f9-c340-e3542afc09d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set - Documents: 11314, Total words: 1166464, Vocabulary size: 101919\n",
            "Test set  - Documents: 7532, Total words: 730769, Vocabulary size: 73050\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract labels from dataset in preparation for build, train, test of Logistic Regression Model\n",
        "y_train = ds_train['label'].tolist()\n",
        "y_test = ds_test['label'].tolist()"
      ],
      "metadata": {
        "id": "S6HeDJVsYpQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build, train, test Logistic Regression Model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "#Create model\n",
        "clf = LogisticRegression(max_iter=1000, random_state=42)\n",
        "#Train model\n",
        "clf.fit(X_train_tfidf, y_train)\n",
        "#Predict on test data\n",
        "y_pred = clf.predict(X_test_tfidf)\n",
        "#Evaluate performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQMnwbHGaHTn",
        "outputId": "cc989971-e467-4b99-e88c-a9cd2ad5a410"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6795\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.45      0.47       319\n",
            "           1       0.60      0.70      0.65       389\n",
            "           2       0.66      0.62      0.64       394\n",
            "           3       0.66      0.62      0.64       392\n",
            "           4       0.77      0.68      0.72       385\n",
            "           5       0.80      0.70      0.75       395\n",
            "           6       0.72      0.79      0.76       390\n",
            "           7       0.77      0.70      0.73       396\n",
            "           8       0.48      0.81      0.60       398\n",
            "           9       0.81      0.79      0.80       397\n",
            "          10       0.88      0.87      0.87       399\n",
            "          11       0.86      0.67      0.75       396\n",
            "          12       0.54      0.59      0.56       393\n",
            "          13       0.76      0.76      0.76       396\n",
            "          14       0.71      0.74      0.72       394\n",
            "          15       0.64      0.79      0.70       398\n",
            "          16       0.58      0.69      0.63       364\n",
            "          17       0.85      0.73      0.78       376\n",
            "          18       0.56      0.44      0.49       310\n",
            "          19       0.51      0.18      0.26       251\n",
            "\n",
            "    accuracy                           0.68      7532\n",
            "   macro avg       0.68      0.67      0.67      7532\n",
            "weighted avg       0.69      0.68      0.68      7532\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Performance Summary**\n",
        "\n",
        "Overall Accuracy: 68%\n",
        "\n",
        "F1-scores: performance varies significantly across classes (e.g., classes 10,6 demonstrate strong performance ~.87-.76, other classes 18,0 demonstrate weaker performance ~.49-.47)\n",
        "\n",
        "Results suggest possible class imbalance with some classes having few samples and lower F1 scores (e.g., class 19 had 251 samples/scored lowest F1=.26 vs. class 2 had 394 samples/scored better F1=.64)\n",
        "\n",
        "Also, potential for false positives as some classes (e.g., 8) showed high recall (e.g., class 8 .81) but low precision (.48).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "g1OD9XQs4xmY"
      }
    }
  ]
}
