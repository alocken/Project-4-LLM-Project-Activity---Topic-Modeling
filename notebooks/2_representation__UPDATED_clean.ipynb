{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project 4: LLM Project Activity - Topic Modeling**\n",
        "### **Week 23** 2-Representation\n",
        "Apply tokenization and text representation methods in the project. (9.3)\n",
        "\n",
        "- First, convert tokens from dataset back to string for feature extraction\n",
        "- Chosen TF-IDF for applying feature extration\n",
        "- One complete, will then build a model using Logistic Regression\n",
        "- Finally, will test the performance of the model against test data"
      ],
      "metadata": {
        "id": "Jf6LsawNkiuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert tokenized text back to string\n",
        "def detokenize(text):\n",
        "    if isinstance(text, list):\n",
        "        return ' '.join(text)\n",
        "    return text\n",
        "\n",
        "new_ds = new_ds.map(lambda example: {'text': detokenize(example['text'])})\n",
        "\n",
        "train_texts = new_ds['train']['text']\n",
        "test_texts = new_ds['test']['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "f2b4e675cabe4af897887a0019c128a9",
            "75a7beb9dcb44b78b84fa456ac73fcac",
            "94c9bf4baecf42a3980fedaed929a72b",
            "3ced0640422647ce9257c1aab58dde49",
            "856de3a1b41b431db4614659b244c331",
            "e58ed127b2984e5b8d4bf348d6a9b9aa",
            "23aae18bdd104c1ebc0869a9492be178",
            "b25ea3af6d354ffabca5545b1aaea741",
            "ba58de54aebf49caa4f1e1ab38e56fac",
            "444076d136854045b4e3b63518af75bf",
            "732fc9c7edb44706b90cab4f707896d5",
            "34114dfde5224465b6af748e8307ee38",
            "d26229eb77664f48b3729d04c6609aba",
            "1058bddaad5545759e9319ba3bb25516",
            "bafccb0b4f0f441e944cfa31dfbbd7e7",
            "f4e871c18b6b4ccaac93e05efdb3f7dc",
            "309a18c3c7d84e8298fc4f144b1ee65e",
            "7826e66c4d954e0abdda7b1914341bf6",
            "c260f0cb58034cc7ac11ad22cd9fe790",
            "fb7f135893db44bdb504d981dd3a38ed",
            "127c64c2cb33458fa3e9d38c214096a3",
            "02de9925731f44ccb96c961cc1d0c0e3"
          ]
        },
        "id": "h6qBt-TmXRWc",
        "outputId": "6e177ff0-5af7-4aea-d120-1c61b52bfe56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/11314 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f2b4e675cabe4af897887a0019c128a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/7532 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34114dfde5224465b6af748e8307ee38"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TF-IDF application for feature extraction\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train = vectorizer.fit_transform(train_texts)\n",
        "X_test = vectorizer.transform(test_texts)\n"
      ],
      "metadata": {
        "id": "S6HeDJVsYpQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prepare lablels\n",
        "y_train = new_ds['train']['label']\n",
        "y_test = new_ds['test']['label']"
      ],
      "metadata": {
        "id": "QVKqPFAdZ9pd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train Logistic Regression Model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQMnwbHGaHTn",
        "outputId": "6937a8fc-f842-4729-9b52-aced9f0b2945"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.45      0.47       319\n",
            "           1       0.60      0.70      0.65       389\n",
            "           2       0.66      0.62      0.64       394\n",
            "           3       0.66      0.62      0.64       392\n",
            "           4       0.77      0.68      0.72       385\n",
            "           5       0.80      0.70      0.75       395\n",
            "           6       0.72      0.79      0.76       390\n",
            "           7       0.77      0.70      0.73       396\n",
            "           8       0.48      0.81      0.60       398\n",
            "           9       0.81      0.79      0.80       397\n",
            "          10       0.88      0.87      0.87       399\n",
            "          11       0.86      0.67      0.75       396\n",
            "          12       0.54      0.59      0.56       393\n",
            "          13       0.76      0.76      0.76       396\n",
            "          14       0.71      0.74      0.72       394\n",
            "          15       0.64      0.79      0.70       398\n",
            "          16       0.58      0.69      0.63       364\n",
            "          17       0.85      0.73      0.78       376\n",
            "          18       0.56      0.44      0.49       310\n",
            "          19       0.51      0.18      0.26       251\n",
            "\n",
            "    accuracy                           0.68      7532\n",
            "   macro avg       0.68      0.67      0.67      7532\n",
            "weighted avg       0.69      0.68      0.68      7532\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Performance Summary**\n",
        "\n",
        "Overall Accuracy: 68%\n",
        "\n",
        "F1-scores: performance varies significantly across classes (e.g., classes 10,6 demonstrate strong performance ~.87-.76, other classes 18,0 demonstrate weaker performance ~.49-.47)\n",
        "\n",
        "Results suggest possible class imbalance (e.g., class 19 had 251 samples/scored lowest F1=.26 vs. class 2 had 394 samples/scored better F1=.64)\n",
        "\n",
        "Also, potential for false positives as some classes (e.g., 8) showed high recall but low precision.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "g1OD9XQs4xmY"
      }
    }
  ]
}