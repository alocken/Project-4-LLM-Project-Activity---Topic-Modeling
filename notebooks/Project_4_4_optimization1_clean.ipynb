{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1cbmHPmWsqhB"
   },
   "source": [
    "# **Project 4: LLM Project Activity - Topic Modeling**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FY9b6iv1Ilm8"
   },
   "source": [
    "### **Week 23** Project 4: 4-optimization\n",
    "* Evaluating and optimizing the project model and creating an LLM Model Report. (9.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_2DyT5yDJgNe",
    "outputId": "75c211f3-2ab1-4e90-caf4-383cb3f5fe5f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acf4e4649c974827aa1895c478fb569c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K3qkmq_JJexd",
    "outputId": "aeae153d-5162-46e0-b4f5-e686c160f632"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "git-lfs is already the newest version (3.0.2-1ubuntu0.3).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
     ]
    }
   ],
   "source": [
    " !apt-get install git-lfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aRLI7GvHLgLd"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yIV-JyLsLsdp"
   },
   "outputs": [],
   "source": [
    "repo_name = \"newsgroups_model\"  #model repo name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wZsz_aiTI5lT",
    "outputId": "bb0bbe6e-0450-49fc-99c6-aeeb026ab3a5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c2850abb5e0404ea52574fa17a97465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#train model, load DistilBert\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\",\n",
    "    num_labels=len(label_names),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-XUU5m34I5i8",
    "outputId": "bd61b076-9a6b-4884-f367-0e6d6f592061"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4dea47d33154282a5a08ab790ab015c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bf0bc1a79e44d2887d00229a28ec245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ab007e4f88472e915f84e47403d73d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#define training hyperparameters in TrainingArguments, choose appropriate metric for model to calculate metrics during training, pass training arguments to Trainer, call train() to finetune model;F1 will determine best model at end\n",
    "#metrics selected: accuracy overall percentage of correctly classified documents and Macro F1 Score to determine mean of precision/recall per class and averaged\n",
    "import numpy as np\n",
    "from evaluate import load\n",
    "\n",
    "# Load all required metrics\n",
    "accuracy = load(\"accuracy\")\n",
    "f1 = load(\"f1\")\n",
    "precision = load(\"precision\")\n",
    "recall = load(\"recall\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
    "        \"f1_macro\": f1.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"],\n",
    "        \"precision\": precision.compute(predictions=preds, references=labels, average=\"macro\")[\"precision\"],\n",
    "        \"recall\": recall.compute(predictions=preds, references=labels, average=\"macro\")[\"recall\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PaNZBcl3I5gs"
   },
   "outputs": [],
   "source": [
    "#model #1: optimize through hyperparameters tuning of reducing per device train batch size (from 16 to 8 to see if able to generlize better on small dataset) and per device eval bath size (reduced to 8, doesn't impact mdoel quality but will impact evaluation speed; to match train batch size), added weight decay to prevent overfitting, and warm up steps to see if increase learning rate\n",
    "repo_name = \"newsgroups_model\"\n",
    "training_args = TrainingArguments(\n",
    "   output_dir=repo_name,\n",
    "   learning_rate=1e-5,  #lower learning rate smaller batch size\n",
    "   per_device_train_batch_size=8,\n",
    "   per_device_eval_batch_size=8,\n",
    "   gradient_accumulation_steps=2,  #simulates batch size of 16\n",
    "   num_train_epochs=2,\n",
    "   weight_decay=0.01,\n",
    "   warmup_ratio=0.1,\n",
    "\n",
    "   eval_strategy=\"epoch\",\n",
    "   save_strategy=\"epoch\",\n",
    "\n",
    "   push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5fJplQgGI5eb"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=eval_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iBGcy7e5I5UC",
    "outputId": "c237905d-5d3c-46a2-f521-17c2354f5415"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
       "            function loadScript(url) {\n",
       "            return new Promise(function(resolve, reject) {\n",
       "                let newScript = document.createElement(\"script\");\n",
       "                newScript.onerror = reject;\n",
       "                newScript.onload = resolve;\n",
       "                document.body.appendChild(newScript);\n",
       "                newScript.src = url;\n",
       "            });\n",
       "            }\n",
       "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
       "            const iframe = document.createElement('iframe')\n",
       "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
       "            document.body.appendChild(iframe)\n",
       "            const handshake = new Postmate({\n",
       "                container: iframe,\n",
       "                url: 'https://wandb.ai/authorize'\n",
       "            });\n",
       "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
       "            handshake.then(function(child) {\n",
       "                child.on('authorize', data => {\n",
       "                    clearTimeout(timeout)\n",
       "                    resolve(data)\n",
       "                });\n",
       "            });\n",
       "            })\n",
       "        });\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
      "wandb: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malia-locken\u001b[0m (\u001b[33malia-locken-lighthouse-labs\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20250701_231942-xdrj6vrb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alia-locken-lighthouse-labs/huggingface/runs/xdrj6vrb' target=\"_blank\">newsgroups_model</a></strong> to <a href='https://wandb.ai/alia-locken-lighthouse-labs/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alia-locken-lighthouse-labs/huggingface' target=\"_blank\">https://wandb.ai/alia-locken-lighthouse-labs/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alia-locken-lighthouse-labs/huggingface/runs/xdrj6vrb' target=\"_blank\">https://wandb.ai/alia-locken-lighthouse-labs/huggingface/runs/xdrj6vrb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1416' max='1416' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1416/1416 21:50, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.319700</td>\n",
       "      <td>1.424123</td>\n",
       "      <td>0.643521</td>\n",
       "      <td>0.618610</td>\n",
       "      <td>0.635969</td>\n",
       "      <td>0.624553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.379700</td>\n",
       "      <td>1.233425</td>\n",
       "      <td>0.663834</td>\n",
       "      <td>0.643437</td>\n",
       "      <td>0.647780</td>\n",
       "      <td>0.645893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1416, training_loss=1.6558053399209922, metrics={'train_runtime': 1338.7347, 'train_samples_per_second': 16.903, 'train_steps_per_second': 1.058, 'total_flos': 2998434498723840.0, 'train_loss': 1.6558053399209922, 'epoch': 2.0})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "orH7GuThJSUe",
    "outputId": "1b25e312-97aa-4b0c-9d0c-0447b05b2c0f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='942' max='942' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [942/942 01:53]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.2334253787994385,\n",
       " 'eval_accuracy': 0.6638343069569835,\n",
       " 'eval_f1_macro': 0.6434372248870809,\n",
       " 'eval_precision': 0.647779574786804,\n",
       " 'eval_recall': 0.6458928223813728,\n",
       " 'eval_runtime': 113.7454,\n",
       " 'eval_samples_per_second': 66.218,\n",
       " 'eval_steps_per_second': 8.282,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VA57uwaGZ3cO"
   },
   "source": [
    "**Outputs Summary:** from epoch 1 to 2, training loss decreased significantly (2.31 to 1.37), validation loss decreased (1.42 to 1.23), and all metrics (accuracy, F1, precision, recall) improved. Model appears to be learning well and generalizing better. The loss and metrics indicate good overall learning progress. Will look to add one additional epoch (increasing from 2 to 3) to see if the model will further improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mOX7PtOkZLct"
   },
   "outputs": [],
   "source": [
    "#model #2: optimize using same hyperparameters but adding in addition epoch to see if performance improvments observed with 3 versus 2\n",
    "repo_name = \"newsgroups_model\"\n",
    "training_args = TrainingArguments(\n",
    "   output_dir=repo_name,\n",
    "   learning_rate=1e-5,  #lower learning rate smaller batch size\n",
    "   per_device_train_batch_size=8,\n",
    "   per_device_eval_batch_size=8,\n",
    "   gradient_accumulation_steps=2,  #simulates batch size of 16\n",
    "   num_train_epochs=3,\n",
    "   weight_decay=0.01,\n",
    "   warmup_ratio=0.1,\n",
    "\n",
    "   eval_strategy=\"epoch\",\n",
    "   save_strategy=\"epoch\",\n",
    "\n",
    "   push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xRzm5ymCZbNG"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=eval_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BEGmVlwjJHlO",
    "outputId": "4ee3f6ea-ea1a-4b85-d17d-7e2693fb4f1e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2124' max='2124' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2124/2124 33:35, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.033700</td>\n",
       "      <td>1.070870</td>\n",
       "      <td>0.687069</td>\n",
       "      <td>0.662192</td>\n",
       "      <td>0.660909</td>\n",
       "      <td>0.669988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.797200</td>\n",
       "      <td>1.056222</td>\n",
       "      <td>0.688263</td>\n",
       "      <td>0.666567</td>\n",
       "      <td>0.676877</td>\n",
       "      <td>0.670685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.648300</td>\n",
       "      <td>1.033279</td>\n",
       "      <td>0.696628</td>\n",
       "      <td>0.674041</td>\n",
       "      <td>0.679325</td>\n",
       "      <td>0.679723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2124, training_loss=0.7969629787006846, metrics={'train_runtime': 2016.4573, 'train_samples_per_second': 16.832, 'train_steps_per_second': 1.053, 'total_flos': 4497651748085760.0, 'train_loss': 0.7969629787006846, 'epoch': 3.0})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sMgwR-hfJHZ9",
    "outputId": "43daaa38-e65e-4667-8f77-717157e4f1f6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='942' max='942' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [942/942 01:53]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.0332790613174438,\n",
       " 'eval_accuracy': 0.6966277217206586,\n",
       " 'eval_f1_macro': 0.6740413540599004,\n",
       " 'eval_precision': 0.6793250251214719,\n",
       " 'eval_recall': 0.6797230401635634,\n",
       " 'eval_runtime': 113.7029,\n",
       " 'eval_samples_per_second': 66.243,\n",
       " 'eval_steps_per_second': 8.285,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bzh2PsmsaYDh"
   },
   "source": [
    "**Outputs Summary:** from epoch 1 to 3, training loss decreased significantly (1.03 to 0.64), validation loss decreased (1.07 to 1.03), and all metrics (accuracy, F1, precision, recall) improved. Model appears to be learning well and generalizing better. The loss and metrics indicate good overall learning progress and it appears adding the additional epoch, and subsequent model outputs, support this conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Jl6C1wlZlNy",
    "outputId": "2b96cac9-95ae-41dd-b4b7-8eb73d586e4a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb241a00ebf04f7595c966f300511def",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading...:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/alocken/newsgroups_model/commit/589a3b34fe845823c367b6f4984c9537791daf79', commit_message='End of training', commit_description='', oid='589a3b34fe845823c367b6f4984c9537791daf79', pr_url=None, repo_url=RepoUrl('https://huggingface.co/alocken/newsgroups_model', endpoint='https://huggingface.co', repo_type='model', repo_id='alocken/newsgroups_model'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#outputs of model #2 are results pushing to Hugging Face Hub for later use\n",
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8xh3Dq0iy4SR",
    "outputId": "97008ec9-6e82-4081-9c4b-9bf601de36b2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6148d97f06504c99a27c1fbaf1bbc232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1047f244cfb42688987b723ef41b682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c510ba9c6c23400d9563b1ef07af1aa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30cb6cad44d948819417f03c333c2255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36f31f8d9f714ed88204f20968552232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef760bb0ac5e4e88ae4825370487d7a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'sci.space', 'score': 0.878742516040802},\n",
       " {'label': 'comp.sys.ibm.pc.hardware', 'score': 0.45447736978530884},\n",
       " {'label': 'comp.sys.mac.hardware', 'score': 0.5598772168159485},\n",
       " {'label': 'rec.sport.hockey', 'score': 0.9507641196250916}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use model to predict on new text using pipelines module\n",
    "\n",
    "from transformers import pipeline\n",
    "data = [\n",
    "    \"The Hubble Space Telescope captured a new image of a galaxy.\",\n",
    "    \"I need help setting up my Linux dual boot system.\",\n",
    "    \"The new graphics card performs exceptionally in gaming benchmarks.\",\n",
    "    \"The Lakers won their game last night against the Bulls.\"\n",
    "]\n",
    "my_model = pipeline(model=\"alocken/newsgroups_model\")\n",
    "my_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "NKdd8fVkzgXE",
    "outputId": "1b7a8b5a-a465-4ed9-beb9-31e122a757a0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'sci.space', 'score': 0.878742516040802}, {'label': 'comp.sys.ibm.pc.hardware', 'score': 0.45447736978530884}, {'label': 'comp.sys.mac.hardware', 'score': 0.5598772168159485}, {'label': 'rec.sport.hockey', 'score': 0.9507641196250916}]\n"
     ]
    }
   ],
   "source": [
    "#Hugging Face Hub\n",
    "classifier = pipeline(\"text-classification\", model=\"alocken/newsgroups_model\")\n",
    "\n",
    "# Run predictions\n",
    "predictions = classifier(data)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "CDJmHaz10juH",
    "outputId": "9e4c2a61-5af2-4408-e9bb-168f7d1b45ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: The Hubble Space Telescope captured a new image of a galaxy.\n",
      "Predicted Label: sci.space, Confidence: 0.88\n",
      "\n",
      "Text: I need help setting up my Linux dual boot system.\n",
      "Predicted Label: comp.sys.ibm.pc.hardware, Confidence: 0.45\n",
      "\n",
      "Text: The new graphics card performs exceptionally in gaming benchmarks.\n",
      "Predicted Label: comp.sys.mac.hardware, Confidence: 0.56\n",
      "\n",
      "Text: The Lakers won their game last night against the Bulls.\n",
      "Predicted Label: rec.sport.hockey, Confidence: 0.95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text, pred in zip(data, predictions):\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Predicted Label: {pred['label']}, Confidence: {pred['score']:.2f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfdFL5NK0Bss"
   },
   "source": [
    "**Evaluating performance of the model on unseen data outputs summary:** the output demonstrates that the model is working correctly and making predictions on the custom data input. Output corresponds to one input sentence from data list, label provides the predicted class, and the score is the model's confidence in the prediction (range 0 to 1).\n",
    "Interpreting the results, it looks like the Hubble Space text received high confidence (0.88) and was correctly interpreted, confidently, that it's related to science/space. In the Linux and gaming benchmarks text, Linux received low confidence and gaming moderate. It appears that there was some uncertainty around how to relate For the Lakers text, it was very confident (0.95) although it was correct in it being a rec sport, it incorrectly predicted hockey instead of basketball. This indicates a false positive.\n",
    "Overall, the model performs well when topics are distinct and demonstrates much lower confidence when the topic is either overlapping or not distinct (unclear or ambiguous). It can misclassify similar domains as well which could be due to fewer examples in one class or class imbalance.\n",
    "To further improve this modelâ€™s performance, a few ideas could be:\n",
    "- fine-tune longer with enhanced hyperparameters\n",
    "- add additional training examples for any underperforming categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YkGAByBZJIMF"
   },
   "source": [
    "Note: below code is notebook cleaning code to support upload to GitHub from Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Lq-Fckp_9uLC",
    "outputId": "5dc661c5-9d3f-409d-9e9d-aead10d6d22f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved current notebook to: Project_4_4_optimization.ipynb\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "import IPython\n",
    "\n",
    "notebook_filename = \"Project_4_4_optimization.ipynb\"\n",
    "\n",
    "# Save current notebook to file system\n",
    "IPython.get_ipython().run_cell_magic('capture', '', f'%%javascript\\nIPython.notebook.save_checkpoint();')\n",
    "print(f\"Saved current notebook to: {notebook_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "U1ICdYa9-O3K",
    "outputId": "a065ab54-3669-4fb9-e1e7-5e27579450f1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-411468b2-1604-4c0b-ba18-38363297afcb\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-411468b2-1604-4c0b-ba18-38363297afcb\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Project_4_4_optimization.ipynb to Project_4_4_optimization.ipynb\n"
     ]
    }
   ],
   "source": [
    "# upload it from your local drive\n",
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "p23TfzX3-Vg5",
    "outputId": "d0b2aed2-4c71-4822-a569-aa017f7b2d1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned notebook saved as: Project_4_4_optimization_clean.ipynb\n"
     ]
    }
   ],
   "source": [
    "import nbformat\n",
    "\n",
    "notebook_filename = \"Project_4_4_optimization.ipynb\"  # Make sure this matches the uploaded filename\n",
    "output_filename = notebook_filename.replace('.ipynb', '_clean.ipynb')\n",
    "\n",
    "# Load the notebook\n",
    "with open(notebook_filename, 'r', encoding='utf-8') as f:\n",
    "    nb = nbformat.read(f, as_version=4)\n",
    "\n",
    "# Clean metadata\n",
    "for cell in nb.cells:\n",
    "    cell.metadata.pop('colab', None)\n",
    "    cell.metadata.pop('widgets', None)\n",
    "nb.metadata.pop('colab', None)\n",
    "nb.metadata.pop('widgets', None)\n",
    "\n",
    "# Save cleaned version\n",
    "with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "    nbformat.write(nb, f)\n",
    "\n",
    "print(f\"Cleaned notebook saved as: {output_filename}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
