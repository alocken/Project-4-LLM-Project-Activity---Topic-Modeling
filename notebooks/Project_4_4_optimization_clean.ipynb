{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1cbmHPmWsqhB"
   },
   "source": [
    "# **Project 4: LLM Project Activity - Topic Modeling**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FY9b6iv1Ilm8"
   },
   "source": [
    "### **Week 23** Project 4: 4-optimization\n",
    "* Evaluating and optimizing the project model and creating an LLM Model Report. (9.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_2DyT5yDJgNe",
    "outputId": "75c211f3-2ab1-4e90-caf4-383cb3f5fe5f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acf4e4649c974827aa1895c478fb569c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K3qkmq_JJexd",
    "outputId": "aeae153d-5162-46e0-b4f5-e686c160f632"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "git-lfs is already the newest version (3.0.2-1ubuntu0.3).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
     ]
    }
   ],
   "source": [
    " !apt-get install git-lfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aRLI7GvHLgLd"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yIV-JyLsLsdp"
   },
   "outputs": [],
   "source": [
    "repo_name = \"newsgroups_model\"  #model repo name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wZsz_aiTI5lT",
    "outputId": "bb0bbe6e-0450-49fc-99c6-aeeb026ab3a5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c2850abb5e0404ea52574fa17a97465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#train model, load DistilBert\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\",\n",
    "    num_labels=len(label_names),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-XUU5m34I5i8",
    "outputId": "bd61b076-9a6b-4884-f367-0e6d6f592061"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4dea47d33154282a5a08ab790ab015c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bf0bc1a79e44d2887d00229a28ec245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ab007e4f88472e915f84e47403d73d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#define training hyperparameters in TrainingArguments, choose appropriate metric for model to calculate metrics during training, pass training arguments to Trainer, call train() to finetune model;F1 will determine best model at end\n",
    "#metrics selected: accuracy overall percentage of correctly classified documents and Macro F1 Score to determine mean of precision/recall per class and averaged\n",
    "import numpy as np\n",
    "from evaluate import load\n",
    "\n",
    "# Load all required metrics\n",
    "accuracy = load(\"accuracy\")\n",
    "f1 = load(\"f1\")\n",
    "precision = load(\"precision\")\n",
    "recall = load(\"recall\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
    "        \"f1_macro\": f1.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"],\n",
    "        \"precision\": precision.compute(predictions=preds, references=labels, average=\"macro\")[\"precision\"],\n",
    "        \"recall\": recall.compute(predictions=preds, references=labels, average=\"macro\")[\"recall\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PaNZBcl3I5gs"
   },
   "outputs": [],
   "source": [
    "#model #1: optimize through hyperparameters tuning of reducing per device train batch size (from 16 to 8 to see if able to generlize better on small dataset) and per device eval bath size (reduced to 8, doesn't impact mdoel quality but will impact evaluation speed; to match train batch size), added weight decay to prevent overfitting, and warm up steps to see if increase learning rate\n",
    "repo_name = \"newsgroups_model\"\n",
    "training_args = TrainingArguments(\n",
    "   output_dir=repo_name,\n",
    "   learning_rate=1e-5,  #lower learning rate smaller batch size\n",
    "   per_device_train_batch_size=8,\n",
    "   per_device_eval_batch_size=8,\n",
    "   gradient_accumulation_steps=2,  #simulates batch size of 16\n",
    "   num_train_epochs=2,\n",
    "   weight_decay=0.01,\n",
    "   warmup_ratio=0.1,\n",
    "\n",
    "   eval_strategy=\"epoch\",\n",
    "   save_strategy=\"epoch\",\n",
    "\n",
    "   push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5fJplQgGI5eb"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=eval_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iBGcy7e5I5UC",
    "outputId": "c237905d-5d3c-46a2-f521-17c2354f5415"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
       "            function loadScript(url) {\n",
       "            return new Promise(function(resolve, reject) {\n",
       "                let newScript = document.createElement(\"script\");\n",
       "                newScript.onerror = reject;\n",
       "                newScript.onload = resolve;\n",
       "                document.body.appendChild(newScript);\n",
       "                newScript.src = url;\n",
       "            });\n",
       "            }\n",
       "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
       "            const iframe = document.createElement('iframe')\n",
       "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
       "            document.body.appendChild(iframe)\n",
       "            const handshake = new Postmate({\n",
       "                container: iframe,\n",
       "                url: 'https://wandb.ai/authorize'\n",
       "            });\n",
       "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
       "            handshake.then(function(child) {\n",
       "                child.on('authorize', data => {\n",
       "                    clearTimeout(timeout)\n",
       "                    resolve(data)\n",
       "                });\n",
       "            });\n",
       "            })\n",
       "        });\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
      "wandb: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malia-locken\u001b[0m (\u001b[33malia-locken-lighthouse-labs\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20250701_231942-xdrj6vrb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alia-locken-lighthouse-labs/huggingface/runs/xdrj6vrb' target=\"_blank\">newsgroups_model</a></strong> to <a href='https://wandb.ai/alia-locken-lighthouse-labs/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alia-locken-lighthouse-labs/huggingface' target=\"_blank\">https://wandb.ai/alia-locken-lighthouse-labs/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alia-locken-lighthouse-labs/huggingface/runs/xdrj6vrb' target=\"_blank\">https://wandb.ai/alia-locken-lighthouse-labs/huggingface/runs/xdrj6vrb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1416' max='1416' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1416/1416 21:50, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.319700</td>\n",
       "      <td>1.424123</td>\n",
       "      <td>0.643521</td>\n",
       "      <td>0.618610</td>\n",
       "      <td>0.635969</td>\n",
       "      <td>0.624553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.379700</td>\n",
       "      <td>1.233425</td>\n",
       "      <td>0.663834</td>\n",
       "      <td>0.643437</td>\n",
       "      <td>0.647780</td>\n",
       "      <td>0.645893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1416, training_loss=1.6558053399209922, metrics={'train_runtime': 1338.7347, 'train_samples_per_second': 16.903, 'train_steps_per_second': 1.058, 'total_flos': 2998434498723840.0, 'train_loss': 1.6558053399209922, 'epoch': 2.0})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "orH7GuThJSUe",
    "outputId": "1b25e312-97aa-4b0c-9d0c-0447b05b2c0f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='942' max='942' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [942/942 01:53]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.2334253787994385,\n",
       " 'eval_accuracy': 0.6638343069569835,\n",
       " 'eval_f1_macro': 0.6434372248870809,\n",
       " 'eval_precision': 0.647779574786804,\n",
       " 'eval_recall': 0.6458928223813728,\n",
       " 'eval_runtime': 113.7454,\n",
       " 'eval_samples_per_second': 66.218,\n",
       " 'eval_steps_per_second': 8.282,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VA57uwaGZ3cO"
   },
   "source": [
    "**Outputs Summary:** from epoch 1 to 2, training loss decreased significantly (2.31 to 1.37), validation loss decreased (1.42 to 1.23), and all metrics (accuracy, F1, precision, recall) improved. Model appears to be learning well and generalizing better. The loss and metrics indicate good overall learning progress. Will look to add one additional epoch (increasing from 2 to 3) to see if the model will further improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mOX7PtOkZLct"
   },
   "outputs": [],
   "source": [
    "#model #2: optimize using same hyperparameters but adding in addition epoch to see if performance improvments observed with 3 versus 2\n",
    "repo_name = \"newsgroups_model\"\n",
    "training_args = TrainingArguments(\n",
    "   output_dir=repo_name,\n",
    "   learning_rate=1e-5,  #lower learning rate smaller batch size\n",
    "   per_device_train_batch_size=8,\n",
    "   per_device_eval_batch_size=8,\n",
    "   gradient_accumulation_steps=2,  #simulates batch size of 16\n",
    "   num_train_epochs=3,\n",
    "   weight_decay=0.01,\n",
    "   warmup_ratio=0.1,\n",
    "\n",
    "   eval_strategy=\"epoch\",\n",
    "   save_strategy=\"epoch\",\n",
    "\n",
    "   push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xRzm5ymCZbNG"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=eval_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BEGmVlwjJHlO",
    "outputId": "4ee3f6ea-ea1a-4b85-d17d-7e2693fb4f1e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2124' max='2124' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2124/2124 33:35, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.033700</td>\n",
       "      <td>1.070870</td>\n",
       "      <td>0.687069</td>\n",
       "      <td>0.662192</td>\n",
       "      <td>0.660909</td>\n",
       "      <td>0.669988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.797200</td>\n",
       "      <td>1.056222</td>\n",
       "      <td>0.688263</td>\n",
       "      <td>0.666567</td>\n",
       "      <td>0.676877</td>\n",
       "      <td>0.670685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.648300</td>\n",
       "      <td>1.033279</td>\n",
       "      <td>0.696628</td>\n",
       "      <td>0.674041</td>\n",
       "      <td>0.679325</td>\n",
       "      <td>0.679723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2124, training_loss=0.7969629787006846, metrics={'train_runtime': 2016.4573, 'train_samples_per_second': 16.832, 'train_steps_per_second': 1.053, 'total_flos': 4497651748085760.0, 'train_loss': 0.7969629787006846, 'epoch': 3.0})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sMgwR-hfJHZ9",
    "outputId": "43daaa38-e65e-4667-8f77-717157e4f1f6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='942' max='942' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [942/942 01:53]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.0332790613174438,\n",
       " 'eval_accuracy': 0.6966277217206586,\n",
       " 'eval_f1_macro': 0.6740413540599004,\n",
       " 'eval_precision': 0.6793250251214719,\n",
       " 'eval_recall': 0.6797230401635634,\n",
       " 'eval_runtime': 113.7029,\n",
       " 'eval_samples_per_second': 66.243,\n",
       " 'eval_steps_per_second': 8.285,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bzh2PsmsaYDh"
   },
   "source": [
    "**Outputs Summary:** from epoch 1 to 3, training loss decreased significantly (1.03 to 0.64), validation loss decreased (1.07 to 1.03), and all metrics (accuracy, F1, precision, recall) improved. Model appears to be learning well and generalizing better. The loss and metrics indicate good overall learning progress and it appears adding the additional epoch, and subsequent model outputs, support this conclusion.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Jl6C1wlZlNy",
    "outputId": "2b96cac9-95ae-41dd-b4b7-8eb73d586e4a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb241a00ebf04f7595c966f300511def",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading...:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/alocken/newsgroups_model/commit/589a3b34fe845823c367b6f4984c9537791daf79', commit_message='End of training', commit_description='', oid='589a3b34fe845823c367b6f4984c9537791daf79', pr_url=None, repo_url=RepoUrl('https://huggingface.co/alocken/newsgroups_model', endpoint='https://huggingface.co', repo_type='model', repo_id='alocken/newsgroups_model'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#outputs of model #2 are results pushing to Hugging Face Hub for later use\n",
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YkGAByBZJIMF"
   },
   "source": [
    "Note: below code is notebook cleaning code to support upload to GitHub from Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lq-Fckp_9uLC"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import IPython\n",
    "\n",
    "notebook_filename = \"Project_4_4_optimization.ipynb\"\n",
    "\n",
    "# Save current notebook to file system\n",
    "IPython.get_ipython().run_cell_magic('capture', '', f'%%javascript\\nIPython.notebook.save_checkpoint();')\n",
    "print(f\"Saved current notebook to: {notebook_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U1ICdYa9-O3K"
   },
   "outputs": [],
   "source": [
    "# upload it from your local drive\n",
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p23TfzX3-Vg5"
   },
   "outputs": [],
   "source": [
    "import nbformat\n",
    "\n",
    "notebook_filename = \"PProject_4_4_optimization.ipynb\"  # Make sure this matches the uploaded filename\n",
    "output_filename = notebook_filename.replace('.ipynb', '_clean.ipynb')\n",
    "\n",
    "# Load the notebook\n",
    "with open(notebook_filename, 'r', encoding='utf-8') as f:\n",
    "    nb = nbformat.read(f, as_version=4)\n",
    "\n",
    "# Clean metadata\n",
    "for cell in nb.cells:\n",
    "    cell.metadata.pop('colab', None)\n",
    "    cell.metadata.pop('widgets', None)\n",
    "nb.metadata.pop('colab', None)\n",
    "nb.metadata.pop('widgets', None)\n",
    "\n",
    "# Save cleaned version\n",
    "with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "    nbformat.write(nb, f)\n",
    "\n",
    "print(f\"Cleaned notebook saved as: {output_filename}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
